{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a79bc72607e46958fb9f1978c94ebee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fb391decf574fce866ebce294e9c0e7",
              "IPY_MODEL_29333ef604a941dd89ade1d35d6fc0b6",
              "IPY_MODEL_ddc2461dc6534564bc30c23a3b0571eb"
            ],
            "layout": "IPY_MODEL_ec07882093984c36a3ffad49509385c6"
          }
        },
        "0fb391decf574fce866ebce294e9c0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_165fb9b00de0480bb17b84e4f1d187a6",
            "placeholder": "​",
            "style": "IPY_MODEL_d9368b1697114adb82ddea84160fc799",
            "value": "Map: 100%"
          }
        },
        "29333ef604a941dd89ade1d35d6fc0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c99b4bc64540bf8cd4753aca1a5577",
            "max": 1066,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba1446f25f844478acdf52dee4e4baaf",
            "value": 1066
          }
        },
        "ddc2461dc6534564bc30c23a3b0571eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4f7708a506425a866ee96f9b95cec3",
            "placeholder": "​",
            "style": "IPY_MODEL_b98d5e7a268b42d8a3b7fd0e7393e1d8",
            "value": " 1066/1066 [00:00&lt;00:00, 8302.28 examples/s]"
          }
        },
        "ec07882093984c36a3ffad49509385c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165fb9b00de0480bb17b84e4f1d187a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9368b1697114adb82ddea84160fc799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0c99b4bc64540bf8cd4753aca1a5577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1446f25f844478acdf52dee4e4baaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de4f7708a506425a866ee96f9b95cec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b98d5e7a268b42d8a3b7fd0e7393e1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasminGarcia1210/TAREAS/blob/main/Practica_3_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Integrantes: **Javier Ricardo Muñoz Castillo - Yasmin Johana Garcia**"
      ],
      "metadata": {
        "id": "CVsr5G_FHPis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción y Objetivo\n",
        "\n",
        "Este notebook tiene como objetivo principal realizar clasificación de texto, comparando dos enfoques diferentes para resolver esta tarea.\n",
        "\n",
        "Se implementará y evaluará un método tradicional basado en la vectorización TF-IDF de los textos seguido de un modelo de red neuronal multicapa (MLP). En paralelo, se utilizará un modelo de Transformers pre-entrenado, específicamente DistilBERT, que será ajustado (fine-tuned) en el dataset de clasificación de texto seleccionado. Finalmente, se compararán los resultados de ambos modelos para determinar cuál ofrece un mejor rendimiento en el dataset dado."
      ],
      "metadata": {
        "id": "-lAvRc8Z-YWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, preparamos el entorno de trabajo instalando las librerías necesarias y configurando parámetros iniciales para asegurar la reproducibilidad de los resultados.\n",
        "\n",
        "Primero, instalamos las librerías clave para este proyecto:\n",
        "- `datasets`: Para cargar y manejar fácilmente datasets comunes de procesamiento de lenguaje natural.\n",
        "- `transformers`: La biblioteca de Hugging Face que proporciona acceso a modelos pre-entrenados como BERT, GPT-2, y DistilBERT, junto con herramientas para tokenización y fine-tuning.\n",
        "- `accelerate`: Una biblioteca para simplificar el entrenamiento de modelos PyTorch en diferentes configuraciones de hardware (CPU, múltiples GPUs).\n",
        "- `scikit-learn`: Una biblioteca fundamental para aprendizaje automático en Python, utilizada aquí para el enfoque tradicional (TF-IDF y MLP) y para métricas de evaluación.\n",
        "- `evaluate`: Una biblioteca de Hugging Face para calcular métricas de evaluación de modelos de forma sencilla.\n",
        "python"
      ],
      "metadata": {
        "id": "N_2hSYBg-xOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, importamos las librerías necesarias para el resto del notebook y fijamos una semilla aleatoria. Fijar la semilla (`set_seed(42)`) es crucial para asegurar que los experimentos sean reproducibles, es decir, que obtengamos los mismos resultados cada vez que ejecutemos el código con la misma configuración.\n",
        "\n",
        "\n",
        "Finalmente, detectamos automáticamente si hay una GPU (CUDA) disponible para acelerar el entrenamiento de los modelos. La variable `DEVICE` almacenará \"cuda\" si se detecta una GPU, o \"cpu\" en caso contrario. El output de la celda mostrará el dispositivo detectado, como se ve a continuación."
      ],
      "metadata": {
        "id": "AiA4nwSI_VYC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MlFl7lDy17jU",
        "outputId": "44766337-e15b-4fa1-e5ec-f43139199632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# %% INSTALACIÓN\n",
        "!pip -q install -U datasets transformers accelerate scikit-learn evaluate\n",
        "\n",
        "# %% IMPORTS Y SEED\n",
        "import os, random, numpy as np, torch\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, cargamos el dataset de Hugging Face `rotten_tomatoes` utilizando la función `load_dataset`. Este dataset es comúnmente utilizado para la clasificación de sentimiento en reseñas de películas.\n",
        "\n",
        "El objeto `raw_ds` es un `DatasetDict` que contiene las diferentes particiones del dataset (típicamente 'train', 'validation', 'test'). Podemos inspeccionar su estructura imprimiéndolo.\n"
      ],
      "metadata": {
        "id": "-ylu_dus_SWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME = \"rotten_tomatoes\"\n",
        "TEXT_COL_HINTS = [\"text\", \"sentence\", \"content\", \"review\", \"tweet\"]  # heurística\n",
        "LABEL_COL_NAME = \"label\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_ds = load_dataset(DATASET_NAME)\n",
        "raw_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nsmz0Ks1_AK",
        "outputId": "efdf0703-89e4-43ba-9515-f5d3ae171e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedemos a detectar automáticamente las columnas relevantes para la tarea de clasificación de texto. Identificamos la columna que contiene el texto (`text_col`) buscando nombres comunes (`TEXT_COL_HINTS`) o, como fallback, la primera columna de tipo string. La columna de etiqueta (`LABEL_COL_NAME`) se asume fija en 'label'.\n",
        "\n",
        "Además, determinamos el número de clases (`num_labels`) y creamos los mapeos entre IDs numéricos y nombres de etiquetas (`id2label`, `label2id`). Esto se hace verificando si la característica de la etiqueta tiene nombres definidos; de lo contrario, inferimos el número de clases a partir del valor máximo de etiqueta.\n"
      ],
      "metadata": {
        "id": "O4nw2pZpAtmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectar automáticamente la columna de texto si es posible\n",
        "candidate_text_cols = [c for c in raw_ds[\"train\"].column_names if c in TEXT_COL_HINTS]\n",
        "text_col = candidate_text_cols[0] if len(candidate_text_cols) > 0 else None\n",
        "\n",
        "if text_col is None:\n",
        "    # Fallback: toma la primera columna de tipo string\n",
        "    for c in raw_ds[\"train\"].column_names:\n",
        "        if raw_ds[\"train\"][c] and isinstance(raw_ds[\"train\"][c][0], str):\n",
        "            text_col = c\n",
        "            break\n",
        "\n",
        "assert text_col is not None, f\"No se pudo detectar columna de texto en {DATASET_NAME}\"\n",
        "\n",
        "# Etiquetas\n",
        "features = raw_ds[\"train\"].features\n",
        "num_labels = None\n",
        "id2label, label2id = None, None\n",
        "\n",
        "if LABEL_COL_NAME in features and hasattr(features[LABEL_COL_NAME], \"names\"):\n",
        "    # Clasificación con etiquetas nombradas\n",
        "    names = features[LABEL_COL_NAME].names\n",
        "    num_labels = len(names)\n",
        "    id2label = {i: n for i, n in enumerate(names)}\n",
        "    label2id = {n: i for i, n in enumerate(names)}\n",
        "else:\n",
        "    # Si no hay nombres, inferimos num_labels por máximo + 1\n",
        "    max_label = max(raw_ds[\"train\"][LABEL_COL_NAME])\n",
        "    num_labels = int(max_label) + 1\n",
        "    id2label = {i: f\"CLASS_{i}\" for i in range(num_labels)}\n",
        "    label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Texto: {text_col} | Etiqueta: {LABEL_COL_NAME} | num_labels: {num_labels}\")\n",
        "raw_ds[\"train\"][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrbCGBD52TUN",
        "outputId": "bed11cfa-d02e-44de-ede0-c05c28723ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: rotten_tomatoes\n",
            "Texto: text | Etiqueta: label | num_labels: 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El output muestra el nombre del dataset, las columnas identificadas para texto y etiqueta, el número de clases detectadas, y un ejemplo del primer elemento del set de entrenamiento, confirmando que las columnas se han detectado correctamente y que las etiquetas tienen el formato esperado."
      ],
      "metadata": {
        "id": "GBjIKbT_BCMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Tradicional: TF-IDF + MLP\n",
        "\n",
        "En esta sección, implementamos un enfoque de clasificación de texto tradicional utilizando la vectorización TF-IDF para representar los documentos y un Perceptrón Multicapa (MLP) como modelo clasificador.\n",
        "\n",
        "Primero, preparamos los datos para el modelo tradicional. Separamos los textos y las etiquetas de los conjuntos de entrenamiento y prueba. Si el dataset original no tiene un split de \"test\", usamos el split de \"validation\" o creamos uno pequeño a partir del conjunto de entrenamiento.\n",
        "\n",
        "Luego, aplicamos `TfidfVectorizer` para transformar los textos en vectores numéricos. TF-IDF (Term Frequency-Inverse Document Frequency) asigna un peso a cada término en un documento que refleja cuán importante es el término en el documento en relación con el corpus completo. Configuramos `max_features` para limitar el tamaño del vocabulario y `ngram_range` para incluir unigramas y bigramas, capturando así algo de contexto secuencial.python\n"
      ],
      "metadata": {
        "id": "8YGunqtCBYec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Extraer textos y etiquetas\n",
        "train_texts = raw_ds[\"train\"][text_col]\n",
        "train_labels = raw_ds[\"train\"][LABEL_COL_NAME]\n",
        "\n",
        "# Muchos datasets ya traen split de test. Si no, usamos validation o hacemos split.\n",
        "if \"test\" in raw_ds:\n",
        "    test_texts = raw_ds[\"test\"][text_col]\n",
        "    test_labels = raw_ds[\"test\"][LABEL_COL_NAME]\n",
        "else:\n",
        "    # fallback: usar \"validation\" si existe\n",
        "    split_name = \"validation\" if \"validation\" in raw_ds else \"train\"\n",
        "    # pequeño split manual si no hay test/validation claro\n",
        "    split = raw_ds[split_name].train_test_split(test_size=0.2, seed=42)\n",
        "    train_texts = split[\"train\"][text_col]\n",
        "    train_labels = split[\"train\"][LABEL_COL_NAME]\n",
        "    test_texts  = split[\"test\"][text_col]\n",
        "    test_labels = split[\"test\"][LABEL_COL_NAME]\n",
        "\n",
        "# Vectorización TF-IDF (puedes ajustar max_features)\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,\n",
        "    ngram_range=(1,2),\n",
        "    strip_accents=\"unicode\",\n",
        "    lowercase=True,\n",
        "    min_df=2\n",
        ")\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test  = vectorizer.transform(test_texts)\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(512,),\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    alpha=1e-4,\n",
        "    batch_size=128,\n",
        "    learning_rate_init=1e-3,\n",
        "    max_iter=10,        # sube a 20-30 si quieres más calidad\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=3,\n",
        "    verbose=False\n",
        ")\n",
        "mlp.fit(X_train, train_labels)\n",
        "pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "acc_mlp = accuracy_score(test_labels, pred_mlp)\n",
        "f1m_mlp = f1_score(test_labels, pred_mlp, average=\"macro\")\n",
        "\n",
        "print(f\"[MLP] Accuracy: {acc_mlp:.4f} | F1-macro: {f1m_mlp:.4f}\")\n",
        "print(\"\\nReporte por clase (MLP):\\n\", classification_report(test_labels, pred_mlp, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVMeopor2Ts4",
        "outputId": "fcaba822-eaa9-4c0b-8d78-38f51c2b1c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MLP] Accuracy: 0.7899 | F1-macro: 0.7898\n",
            "\n",
            "Reporte por clase (MLP):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7977    0.7767    0.7871       533\n",
            "           1     0.7824    0.8030    0.7926       533\n",
            "\n",
            "    accuracy                         0.7899      1066\n",
            "   macro avg     0.7901    0.7899    0.7898      1066\n",
            "weighted avg     0.7901    0.7899    0.7898      1066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de vectorizar los datos, definimos y entrenamos un `MLPClassifier`. Un MLP es una red neuronal feedforward simple con una o más capas ocultas. Configuramos una capa oculta con 512 neuronas, usamos la función de activación ReLU, el optimizador Adam, y un número limitado de épocas (`max_iter=10`) con `early_stopping` para prevenir sobreajuste.\n",
        "\n",
        "Una vez entrenado el modelo, realizamos predicciones sobre el conjunto de prueba (`X_test`) y evaluamos su rendimiento utilizando `accuracy_score` y `f1_score` con promedio \"macro\". También generamos un `classification_report` para ver métricas por clase (precisión, recall, f1-score).\n",
        "\n",
        "El output muestra la Accuracy y el F1-macro general del modelo MLP, seguido de un reporte detallado por cada clase. Estos resultados nos dan una primera indicación de qué tan bien se desempeña el modelo tradicional en la tarea de clasificación de texto.\n",
        "Accuracy (0.7899): El modelo clasificó correctamente aproximadamente el 79% de las reseñas en el conjunto de prueba.\n",
        "F1-macro (0.7898): El F1-macro, que es un promedio del F1-score para cada clase (considerando tanto precisión como recall), también es de aproximadamente 0.79. Esto indica un rendimiento equilibrado entre las dos clases ('negativa' y 'positiva').\n",
        "Reporte por clase:\n",
        "Para la clase 0 (negativa): La precisión es 0.7977 (de todas las reseñas predichas como negativas, casi el 80% eran realmente negativas) y el recall es 0.7767 (de todas las reseñas realmente negativas, casi el 78% fueron identificadas por el modelo). El F1-score es 0.7871.\n",
        "Para la clase 1 (positiva): La precisión es 0.7824 (de todas las reseñas predichas como positivas, aproximadamente el 78% eran realmente positivas) y el recall es 0.8030 (de todas las reseñas realmente positivas, aproximadamente el 80% fueron identificadas por el modelo). El F1-score es 0.7926.\n",
        "Conclusión del modelo MLP:\n",
        "\n",
        "El modelo MLP con TF-IDF muestra un rendimiento razonable para la clasificación de sentimientos en este dataset, con una precisión y recall similares para ambas clases. Los valores de Accuracy y F1-macro alrededor del 79% sugieren que el modelo es capaz de realizar la tarea, aunque hay margen de mejora.\n",
        "\n",
        "Más adelante en el notebook, compararás estos resultados con el modelo basado en Transformers para ver cuál enfoque es más efectivo."
      ],
      "metadata": {
        "id": "IsZkNIq3BuoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, implementamos un enfoque de clasificación de texto utilizando un modelo de Transformers pre-entrenado de Hugging Face, específicamente DistilBERT. Los modelos Transformer han demostrado ser muy efectivos en una amplia gama de tareas de PLN debido a su capacidad para capturar relaciones contextuales complejas en el texto. Ajustaremos (fine-tune) DistilBERT en nuestro dataset para adaptarlo a la tarea de clasificación de texto.\n",
        "\n",
        "Primero, cargamos el tokenizador y el modelo pre-entrenado. El tokenizador (`AutoTokenizer`) convierte el texto crudo en IDs numéricos que el modelo puede entender, mientras que `AutoModelForSequenceClassification` carga la arquitectura del modelo Transformer junto con una capa adicional para la clasificación de secuencias. Especificamos el punto de control (`model_ckpt`, aquí \"distilbert-base-uncased\") para cargar los pesos pre-entrenados.\n"
      ],
      "metadata": {
        "id": "wosXl6CdDO3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"   # puedes cambiar a 'bert-base-uncased', 'roberta-base', etc.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[text_col], truncation=True)\n",
        "\n",
        "tokenized = raw_ds.map(tokenize_fn, batched=True, remove_columns=[c for c in raw_ds[\"train\"].column_names if c not in [text_col, LABEL_COL_NAME]])\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Preparar splits\n",
        "train_ds = tokenized[\"train\"]\n",
        "test_ds  = tokenized[\"test\"] if \"test\" in tokenized else tokenized[\"validation\"] if \"validation\" in tokenized else tokenized[\"train\"].train_test_split(0.2, seed=42)[\"test\"]\n",
        "\n",
        "# Cargar modelo\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "metric_acc = evaluate.load(\"accuracy\")\n",
        "metric_f1  = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    f1m = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1m}\n",
        "\n",
        "fp16 = (DEVICE == \"cuda\")\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"outputs\",\n",
        "    eval_strategy=\"epoch\", # Changed evaluation_strategy to eval_strategy\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=50,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=2,   # sube a 3-5 si tienes tiempo\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=fp16,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "train_result = trainer.train()\n",
        "eval_result  = trainer.evaluate()\n",
        "eval_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "3a79bc72607e46958fb9f1978c94ebee",
            "0fb391decf574fce866ebce294e9c0e7",
            "29333ef604a941dd89ade1d35d6fc0b6",
            "ddc2461dc6534564bc30c23a3b0571eb",
            "ec07882093984c36a3ffad49509385c6",
            "165fb9b00de0480bb17b84e4f1d187a6",
            "d9368b1697114adb82ddea84160fc799",
            "b0c99b4bc64540bf8cd4753aca1a5577",
            "ba1446f25f844478acdf52dee4e4baaf",
            "de4f7708a506425a866ee96f9b95cec3",
            "b98d5e7a268b42d8a3b7fd0e7393e1d8"
          ]
        },
        "id": "BFLrVcEz2XZ6",
        "outputId": "c0d7fccf-b331-48f7-bfce-702cee2f5515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a79bc72607e46958fb9f1978c94ebee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1464984504.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1068/1068 00:45, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.356500</td>\n",
              "      <td>0.398387</td>\n",
              "      <td>0.828330</td>\n",
              "      <td>0.827333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.243800</td>\n",
              "      <td>0.420679</td>\n",
              "      <td>0.835835</td>\n",
              "      <td>0.835802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [34/34 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4206790328025818,\n",
              " 'eval_accuracy': 0.8358348968105066,\n",
              " 'eval_f1_macro': 0.8358023854643524,\n",
              " 'eval_runtime': 0.4729,\n",
              " 'eval_samples_per_second': 2254.082,\n",
              " 'eval_steps_per_second': 71.894,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Una vez que hemos entrenado y evaluado ambos modelos, el tradicional (MLP con TF-IDF) y el basado en Transformers (DistilBERT), procedemos a comparar su rendimiento para determinar cuál es superior en la tarea de clasificación de texto para este dataset.\n",
        "\n",
        "La comparación se basa principalmente en las métricas de evaluación obtenidas en el conjunto de prueba: **Accuracy** y **F1-macro**. La Accuracy mide la proporción de predicciones correctas en general, mientras que el F1-macro es el promedio no ponderado del F1-score por cada clase, siendo una métrica más robusta en casos donde las clases podrían estar desbalanceadas (aunque en este dataset particular, no es el caso).\n",
        "\n",
        "Para facilitar la comparación visual, consolidamos los resultados de ambos modelos en un DataFrame de pandas llamado `resumen`"
      ],
      "metadata": {
        "id": "GehqsMMTEZQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_trf = eval_result.get(\"eval_accuracy\", None)\n",
        "f1m_trf = eval_result.get(\"eval_f1_macro\", None)\n",
        "\n",
        "resumen = pd.DataFrame([\n",
        "    {\"Modelo\": \"MLP (TF-IDF)\", \"Accuracy\": acc_mlp, \"F1-macro\": f1m_mlp},\n",
        "    {\"Modelo\": \"DistilBERT\",   \"Accuracy\": acc_trf, \"F1-macro\": f1m_trf},\n",
        "])\n",
        "resumen\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "KOqRcr122cQF",
        "outputId": "5799dbb2-f3d2-4d43-bbda-a383175b6d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Modelo  Accuracy  F1-macro\n",
              "0  MLP (TF-IDF)  0.789869  0.789832\n",
              "1    DistilBERT  0.835835  0.835802"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36f2c347-a6cc-4f10-8b8f-600286b5fd0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLP (TF-IDF)</td>\n",
              "      <td>0.789869</td>\n",
              "      <td>0.789832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DistilBERT</td>\n",
              "      <td>0.835835</td>\n",
              "      <td>0.835802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36f2c347-a6cc-4f10-8b8f-600286b5fd0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36f2c347-a6cc-4f10-8b8f-600286b5fd0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36f2c347-a6cc-4f10-8b8f-600286b5fd0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49463aa2-b652-4dab-a244-9fac1f70773b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49463aa2-b652-4dab-a244-9fac1f70773b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49463aa2-b652-4dab-a244-9fac1f70773b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b044a1e1-7577-4082-a553-c1b138d07356\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resumen')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b044a1e1-7577-4082-a553-c1b138d07356 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resumen');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resumen",
              "summary": "{\n  \"name\": \"resumen\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Modelo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"DistilBERT\",\n          \"MLP (TF-IDF)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03250303215585449,\n        \"min\": 0.7898686679174484,\n        \"max\": 0.8358348968105066,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8358348968105066,\n          0.7898686679174484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03250567574667659,\n        \"min\": 0.7898324179693001,\n        \"max\": 0.8358023854643524,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8358023854643524,\n          0.7898324179693001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este DataFrame muestra claramente la Accuracy y el F1-macro para cada modelo. Generalmente, utilizamos el **F1-macro** como la métrica principal para decidir cuál modelo es el \"mejor\", ya que proporciona una visión más equilibrada del rendimiento a través de todas las clases, evitando que una clase mayoritaria enmascare un mal rendimiento en clases minoritarias.\n",
        "\n",
        "Basándonos en los valores del F1-macro reportados en la tabla `resumen`, podemos identificar qué modelo ha tenido un desempeño superior en el conjunto de prueba. El código siguiente determina automáticamente si el modelo Transformer (`use_trf`) es el mejor basándose en el F1-macro:\n"
      ],
      "metadata": {
        "id": "wzYX5yIOEs-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Si DistilBERT gana, calculamos sus predicciones para matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def predict_transformer_texts(texts, batch_size=64):\n",
        "    # Tokenizamos en lotes para ahorrar memoria\n",
        "    preds = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        enc = tokenizer(batch, truncation=True, padding=True, return_tensors=\"pt\").to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            out = model(**enc).logits\n",
        "        preds.extend(out.argmax(dim=-1).cpu().numpy().tolist())\n",
        "    return np.array(preds)\n",
        "\n",
        "# Elegimos el mejor por F1-macro\n",
        "use_trf = (f1m_trf is not None) and (f1m_trf >= f1m_mlp)\n",
        "print(\"Usando para matriz de confusión:\", \"DistilBERT\" if use_trf else \"MLP\")\n",
        "\n",
        "if use_trf:\n",
        "    compare_texts = test_texts\n",
        "    compare_true  = test_labels\n",
        "    preds_best    = predict_transformer_texts(compare_texts)\n",
        "else:\n",
        "    compare_true  = test_labels\n",
        "    preds_best    = pred_mlp\n",
        "\n",
        "cm = confusion_matrix(compare_true, preds_best, labels=sorted(set(compare_true)))\n",
        "cm\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=id2label.values(), yticklabels=id2label.values())\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Valor Verdadero\")\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "9hFkiwTx2d52",
        "outputId": "440ba4df-b730-415c-ae67-112df4f72843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando para matriz de confusión: DistilBERT\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida de la celda que genera la matriz de confusión nos confirma qué modelo (`MLP` o `DistilBERT`) fue seleccionado como el mejor basado en esta comparación de métricas. En este caso, como se puede observar en el output de la celda original, DistilBERT es seleccionado.\n",
        "\n",
        "# Matriz de Confusión para el Mejor Modelo\n",
        "\n",
        "Para tener una comprensión más detallada del rendimiento del mejor modelo (determinado por el F1-macro, que en este caso fue DistilBERT), calculamos y analizamos su matriz de confusión.\n",
        "\n",
        "Una **matriz de confusión** es una tabla que visualiza el rendimiento de un algoritmo de clasificación. Cada fila de la matriz representa las instancias en una clase real (verdadera), mientras que cada columna representa las instancias en una clase predicha. Esto nos permite ver no solo cuántas predicciones fueron correctas, sino también dónde el modelo se equivocó (es decir, qué tipos de errores de clasificación cometió).\n",
        "\n",
        "La matriz de confusión para un problema de clasificación binaria como este (clases 'neg' y 'pos') típicamente tiene la siguiente estructura:\n",
        "\n",
        "|               | Predicho Negativo | Predicho Positivo |\n",
        "|---------------|-------------------|-------------------|\n",
        "| **Real Negativo** | Verdaderos Negativos (TN) | Falsos Positivos (FP)   |\n",
        "| **Real Positivo** | Falsos Negativos (FN)   | Verdaderos Positivos (TP) |\n",
        "\n",
        "- **Verdaderos Positivos (TP):** El modelo predijo correctamente la clase positiva.\n",
        "- **Verdaderos Negativos (TN):** El modelo predijo correctamente la clase negativa.\n",
        "- **Falsos Positivos (FP):** El modelo predijo la clase positiva, pero la clase real era negativa (Error de Tipo I).\n",
        "- **Falsos Negativos (FN):** El modelo predijo la clase negativa, pero la clase real era positiva (Error de Tipo II).\n",
        "\n",
        "La matriz de confusión se calcula utilizando la función `confusion_matrix` de `sklearn.metrics`, comparando las etiquetas verdaderas (`compare_true`) con las predicciones del mejor modelo (`preds_best`).\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "12yLdfVaE-6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretación (para clases 0: 'neg', 1: 'pos'):\n",
        "- **454 TN**: El modelo clasificó correctamente 454 reseñas negativas como negativas.\n",
        "- **79 FP**: El modelo clasificó incorrectamente 79 reseñas negativas como positivas.\n",
        "- **91 FN**: El modelo clasificó incorrectamente 91 reseñas positivas como negativas.\n",
        "- **442 TP**: El modelo clasificó correctamente 442 reseñas positivas como positivas."
      ],
      "metadata": {
        "id": "EOxtEfTUECRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PIqQh4Bn_qTr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae239e9"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **¿Cuál era el objetivo principal de este notebook?**\n",
        "    El objetivo principal era realizar clasificación de texto comparando un enfoque tradicional (TF-IDF + MLP) con un modelo basado en Transformers (DistilBERT).\n",
        "\n",
        "2.  **¿Qué modelos se compararon en este análisis?**\n",
        "    Se compararon un modelo de Perceptrón Multicapa (MLP) utilizando características extraídas con TF-IDF, y un modelo DistilBERT pre-entrenado ajustado (fine-tuned) para la tarea de clasificación.\n",
        "\n",
        "3.  **¿Cómo se seleccionó el mejor modelo?**\n",
        "    El mejor modelo se seleccionó comparando las métricas de evaluación Accuracy y F1-macro en el conjunto de prueba, dando preferencia al F1-macro por ser más robusto en caso de desbalance de clases.\n",
        "\n",
        "4.  **¿Qué información adicional proporcionó la matriz de confusión?**\n",
        "    La matriz de confusión para el mejor modelo (DistilBERT) mostró el número de Verdaderos Positivos, Verdaderos Negativos, Falsos Positivos y Falsos Negativos, indicando que el modelo tuvo un desempeño similar al clasificar correctamente ambas clases y que cometió un número comparable de Falsos Positivos (79) y Falsos Negativos (91).\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   El dataset \"rotten\\_tomatoes\" fue cargado exitosamente, identificando automáticamente las columnas de texto y etiqueta y determinando el número de clases (2: 'neg', 'pos').\n",
        "*   Se implementó y evaluó un modelo tradicional de clasificación de texto usando vectorización TF-IDF y un clasificador MLP.\n",
        "*   Se implementó y evaluó un modelo basado en Transformers (DistilBERT) mediante fine-tuning en el dataset, utilizando el tokenizador y modelo de Hugging Face.\n",
        "*   La comparación de métricas de evaluación (Accuracy y F1-macro) mostró que el modelo DistilBERT tuvo un rendimiento superior al modelo MLP con TF-IDF. (Aunque las métricas exactas no se pudieron incluir en el resumen final debido a las limitaciones de generación, el proceso de comparación se explicó y se identificó a DistilBERT como el mejor).\n",
        "*   La matriz de confusión para el mejor modelo (DistilBERT) reveló que tuvo un desempeño similar al clasificar correctamente reseñas negativas (454 TN) y positivas (442 TP), con errores de clasificación (79 FP y 91 FN) distribuidos de manera relativamente equitativa entre los dos tipos.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   El uso de modelos Transformers pre-entrenados y ajustados (fine-tuning) demostró ser significativamente más efectivo para la clasificación de texto en este dataset en comparación con un enfoque tradicional basado en TF-IDF y MLP.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiVIcZDbOv84"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}